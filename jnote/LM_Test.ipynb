{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os,glob\n",
    "\n",
    "def sample_generator(filenames, wordspath, maxlen=100, minlen=10):\n",
    "    def create_vocab(wpath):\n",
    "        w2id = {}\n",
    "        id2w = {}\n",
    "        def add_word(vocab, word):\n",
    "            vocab[word] = len(vocab)\n",
    "        add_word(w2id, '<pad>')\n",
    "        add_word(w2id, '<unk>')\n",
    "        add_word(w2id, '<bos>')\n",
    "        add_word(w2id, '<eos>')\n",
    "        with open(wordspath) as fd:\n",
    "            for line in fd:\n",
    "                w, freq = line.strip().split('\\t')\n",
    "                add_word(w2id, w)\n",
    "        for w in w2id:\n",
    "            id2w[w2id[w]] = w\n",
    "        return w2id, id2w\n",
    "    \n",
    "    def read_one_file(file, vocab, maxlen, minlen):\n",
    "        with open(file) as fd:\n",
    "            for line in fd:\n",
    "                if not line.isspace():\n",
    "                    wids = [vocab[w] if w in vocab else vocab['<unk>'] \n",
    "                           for w in list(''.join(line.strip().split()))]\n",
    "                    if len(wids) < minlen or len(wids)>=maxlen:\n",
    "                        continue\n",
    "                    yield ([vocab['<bos>']] + wids, wids + [vocab['<eos>']], len(wids)+1)\n",
    "                    \n",
    "    w2id, id2w = create_vocab(wordspath)\n",
    "    if isinstance(filenames, list):\n",
    "        np.random.shuffle(filenames)\n",
    "        for f in filenames:\n",
    "            for d in read_one_file(f, w2id, maxlen, minlen):\n",
    "                yield d\n",
    "    else:\n",
    "        for d in read_one_file(filenames, w2id, maxlen, minlen):\n",
    "            yield d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.feature_column import feature_column_lib\n",
    "\n",
    "def input_fn():\n",
    "    datagen = sample_generator(glob.glob('./wiki_0000'), './words.txt')\n",
    "\n",
    "    ds = tf.data.TextLineDataset.from_generator(lambda: datagen, (tf.int32, tf.int32, tf.int32),\n",
    "                                           (tf.TensorShape([None]), tf.TensorShape([None]), tf.TensorShape([])))\n",
    "    ds = ds.take(100)\n",
    "    ds = ds.shuffle(buffer_size=100000)\n",
    "    ds = ds.padded_batch(10, (tf.TensorShape([None]),\n",
    "                              tf.TensorShape([None]),\n",
    "                              tf.TensorShape([])))\n",
    "    ds = ds.map(lambda a, b, c: ({'f_wids': a, 'f_len': c}, b))\n",
    "    ds = ds.prefetch(5)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def my_model(features, labels, mode, params):\n",
    "    \"\"\"DNN with three hidden layers and learning_rate=0.1.\"\"\"\n",
    "    in_x, in_len = features['f_wids'], features['f_len']\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': features,\n",
    "            'logits': features\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "    # Create training op.\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "def main():\n",
    "\n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=my_model, params={})\n",
    "    predictions = classifier.predict(input_fn=lambda: gendata())\n",
    "\n",
    "    print([o for o in predictions])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/5r/zhr6xl0j4hlgsj6383x59_g40000gn/T/tmpx9d7sq0p\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/5r/zhr6xl0j4hlgsj6383x59_g40000gn/T/tmpx9d7sq0p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb41882898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Could not find trained model in model_dir: /var/folders/5r/zhr6xl0j4hlgsj6383x59_g40000gn/T/tmpx9d7sq0p, running initialization to predict.\n",
      "WARNING:tensorflow:From /Users/jerrik/a3/envs/tf1.13/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/jerrik/a3/envs/tf1.13/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[{'class_ids': 2, 'logits': 2}, {'class_ids': 9, 'logits': 9}, {'class_ids': 0, 'logits': 0}, {'class_ids': 6, 'logits': 6}, {'class_ids': 4, 'logits': 4}, {'class_ids': 1, 'logits': 1}, {'class_ids': 7, 'logits': 7}, {'class_ids': 5, 'logits': 5}, {'class_ids': 3, 'logits': 3}, {'class_ids': 8, 'logits': 8}, {'class_ids': 1, 'logits': 1}, {'class_ids': 9, 'logits': 9}, {'class_ids': 0, 'logits': 0}, {'class_ids': 7, 'logits': 7}, {'class_ids': 4, 'logits': 4}, {'class_ids': 2, 'logits': 2}, {'class_ids': 8, 'logits': 8}, {'class_ids': 3, 'logits': 3}, {'class_ids': 6, 'logits': 6}, {'class_ids': 5, 'logits': 5}]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.feature_column import feature_column_lib\n",
    "\n",
    "\n",
    "aa = [o for o in range(10)]\n",
    "def gen(x):\n",
    "    np.random.shuffle(x)\n",
    "    for i in x:\n",
    "        yield (i, i)\n",
    "def gendata():\n",
    "    ds = tf.data.TextLineDataset.from_generator(lambda: gen(aa), (tf.int32, tf.int32),\n",
    "                                                (tf.TensorShape([]), tf.TensorShape([])))\n",
    "    ds = ds.batch(3).repeat(2)\n",
    "    return ds\n",
    "\n",
    "def my_model(features, labels, mode, params):\n",
    "    \"\"\"DNN with three hidden layers and learning_rate=0.1.\"\"\"\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class_ids': features,\n",
    "            'logits': features\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "def main():\n",
    "\n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=my_model, params={})\n",
    "    predictions = classifier.predict(input_fn=lambda: gendata())\n",
    "\n",
    "    print([o for o in predictions])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle\n",
      "[1 2 9]\n",
      "[7 8 3]\n",
      "[ 4  6 10]\n",
      "[5]\n",
      "shuffle\n",
      "[3 1 4]\n",
      "[10  8  2]\n",
      "[6 5 9]\n",
      "[7]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import session as tf_sesstion\n",
    "# from tensorflow.python import ops\n",
    "import numpy as np\n",
    "aa = [o for o in range(10)]\n",
    "def gen(x):\n",
    "    print('shuffle')\n",
    "    np.random.shuffle(x)\n",
    "    for i in x:\n",
    "        yield i\n",
    "def gendata():\n",
    "    ds = tf.data.TextLineDataset.from_generator(lambda: gen(aa), \n",
    "                                                (tf.int32), (tf.TensorShape([])))\n",
    "    ds = ds.batch(3).repeat(2)\n",
    "    return ds\n",
    "\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    ds = gendata()\n",
    "    ds = ds.make_one_shot_iterator()\n",
    "    out = ds.get_next()\n",
    "    c = out + tf.constant(1, dtype=tf.int32)\n",
    "#     a = tf.constant(1.0, dtype=tf.float32)\n",
    "#     b = tf.constant(2.3, dtype=tf.float32)\n",
    "#     c = a + b\n",
    "with tf_sesstion.Session(graph=g) as sess:\n",
    "    for i in range(20):\n",
    "        try: \n",
    "            print(sess.run(c))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle\n",
      "[9.3 8.3 3.3]\n",
      "[10.3  4.3  5.3]\n",
      "[ 2.3 11.3  7.3]\n",
      "[6.3]\n",
      "shuffle\n",
      "[ 2.3  7.3 10.3]\n",
      "[ 9.3  3.3 11.3]\n",
      "[6.3 5.3 8.3]\n",
      "[4.3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import session as tf_sesstion\n",
    "# from tensorflow.python import ops\n",
    "import numpy as np\n",
    "aa = [o for o in range(10)]\n",
    "def gen(x):\n",
    "    print('shuffle')\n",
    "    np.random.shuffle(x)\n",
    "    for i in x:\n",
    "        yield i\n",
    "def gendata():\n",
    "    ds = tf.data.TextLineDataset.from_generator(lambda: gen(aa), \n",
    "                                                (tf.float32), (tf.TensorShape([])))\n",
    "    ds = ds.batch(3).repeat(2)\n",
    "    return ds\n",
    "@tf.function\n",
    "def run():\n",
    "    ds = gendata()\n",
    "    ds = ds.make_one_shot_iterator()\n",
    "    ds = ds.get_next()\n",
    "    c = ds + tf.constant(1, dtype=tf.float32)\n",
    "    return c\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    cc = run()+1.3\n",
    "\n",
    "\n",
    "with tf_sesstion.Session(graph=g) as sess:\n",
    "    for i in range(20):\n",
    "        try: \n",
    "            print(sess.run(cc))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle\n",
      "tf.Tensor([7. 2. 4.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([ 5.  8. 10.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([1. 3. 6.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([9.], shape=(1,), dtype=float32)\n",
      "shuffle\n",
      "tf.Tensor([6. 2. 9.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([1. 7. 4.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([5. 8. 3.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([10.], shape=(1,), dtype=float32)\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "End of sequence\n\t [[{{node IteratorGetNextSync}}]] [Op:__inference_run_3021]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-8804c640fea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/a3/envs/tf2.0/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/a3/envs/tf2.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/a3/envs/tf2.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \"\"\"\n\u001b[1;32m    573\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 574\u001b[0;31m         (t for t in nest.flatten((args, kwargs))\n\u001b[0m\u001b[1;32m    575\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    576\u001b[0m                            resource_variable_ops.ResourceVariable))))\n",
      "\u001b[0;32m~/a3/envs/tf2.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/a3/envs/tf2.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/a3/envs/tf2.0/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/a3/envs/tf2.0/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNextSync}}]] [Op:__inference_run_3021]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import session as tf_sesstion\n",
    "# from tensorflow.python import ops\n",
    "import numpy as np\n",
    "aa = [o for o in range(10)]\n",
    "def gen(x):\n",
    "    print('shuffle')\n",
    "    np.random.shuffle(x)\n",
    "    for i in x:\n",
    "        yield i\n",
    "def gendata():\n",
    "    ds = tf.data.TextLineDataset.from_generator(lambda: gen(aa), \n",
    "                                                (tf.float32), (tf.TensorShape([])))\n",
    "    ds = ds.batch(3).repeat(2)\n",
    "    return ds\n",
    "ds = gendata()\n",
    "ds = ds.make_one_shot_iterator()\n",
    "@tf.function\n",
    "def run():\n",
    "    out = ds.get_next()\n",
    "    c = out + tf.constant(1, dtype=tf.float32)\n",
    "    return c\n",
    "for i in range(10):\n",
    "    print(run())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "sys.path.append(\"..\")\n",
    "from LM.LMdataset import Dataset\n",
    "ds_fn = Dataset(filepath='./', wordpath='./',batch_size=16, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = type('', (), {})()\n",
    "\n",
    "config.optimizer = 'adam'\n",
    "\n",
    "config.pre_trained = False\n",
    "config.partial_update_until_epoch = 0\n",
    "config.vocab_sz = 4135\n",
    "\n",
    "config.embed_size = 32\n",
    "config.hidden_size = 64\n",
    "\n",
    "config.lr = 0.0001\n",
    "config.decay_steps = 1000\n",
    "config.decay_rate = 0.9\n",
    "config.dropout = 0.2\n",
    "config.reg = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jerrik/a3/envs/tf1.13/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/5r/zhr6xl0j4hlgsj6383x59_g40000gn/T/tmp6l6qg7c4\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/5r/zhr6xl0j4hlgsj6383x59_g40000gn/T/tmp6l6qg7c4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c44e65a90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "from LM.model import model\n",
    "my_model = model(config)\n",
    "\n",
    "est_model = tf.estimator.Estimator(model_fn=my_model, params={})\n",
    "# est_model.train(input_fn=ds_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4131    8383   27900 words.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.arr = {}\n",
    "        \n",
    "    def P(self, n, l, k):\n",
    "        if n == 0 or n == l:\n",
    "            return 0\n",
    "        if n < l:\n",
    "            return float('inf')\n",
    "        if (n, l, k) not in self.arr:\n",
    "            return min(1+self.P(n, l+k, k), 2+self.P(n, 2*l, l)) #min(paste, copy&paste)\n",
    "        else:\n",
    "            return self.arr[(n, l, k)]\n",
    "    \n",
    "    \n",
    "    def minSteps(self, n):\n",
    "        \"\"\"\n",
    "        :type n: int\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        if n <= 1:\n",
    "            return 0\n",
    "        return 1+ self.P(n, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
